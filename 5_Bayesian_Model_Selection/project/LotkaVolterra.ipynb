{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac1e6b53",
   "metadata": {},
   "source": [
    "# Bayesian Model Identification on Lotka-Volterra System Data\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jonathon-langford/aims-inference-2026/blob/main/5_Bayesian_Model_Selection/project/LotkaVolterra.ipynb)\n",
    "\n",
    "This notebook is adapted from the [Symbolic Model Workshop Notebook](https://github.com/SymbolicModel/PySINDy_Tutorial/blob/main/1_SINDy_ODE.ipynb) written by Urban Fasel (2025).\n",
    "\n",
    "This tutorial demonstrates how to apply the principles of Bayesian model selection to discover the governing equations of the predator-prey population dynamics directly from noisy data.\n",
    "\n",
    "The Lotka-Volterra equation is the most rudimentary equation that describes the population dynamics of predator and prey. It is defined by the following set of nonlinear ordinary differential equations:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\dot{x} &= \\alpha x - \\beta xy \\\\\n",
    "\\dot{y} &= \\delta uv - \\gamma y \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Here, ${x}$ and ${y}$ are the population of prey and predator respectively, $\\alpha$, $\\beta$, $\\gamma$, and $\\delta$ are system parameters, and $\\dot{x}$ and $\\dot{y}$ represent the derivatives of the state variables with respect to time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd22bd",
   "metadata": {},
   "source": [
    "# Tutorial to warm up \n",
    "This part of this notebook is to get you warmed up for the real project. By completing this notebook, you should understand:\n",
    "- how to approach the problem of learning a dynamical model from time-series data assuming the model is time-invariant\n",
    "- how to approximate time-derivatives from observed data\n",
    "- how to design a library of candidate functions\n",
    "- how to perform regression on the data given the library\n",
    "- how to select the best model\n",
    "- how to evaluate and validate the model\n",
    "\n",
    "In the real project (see below), the workflow would be similar, but the data is much more challenge and open-ended.\n",
    "\n",
    "The tutorial is split into five steps:\n",
    "\n",
    "- Generate noisy data: integrate the prey and predator system ODE and add Gaussian white noise\n",
    "- Compute derivatives: using finite difference\n",
    "- Build the library $\\Theta$, here using polynomials up to order 3\n",
    "- Compute Bayesian sparse regression\n",
    "- Evaluate the performance of the identified model for forecasting\n",
    "\n",
    "Make sure you have the required libraries installed, e.g. !pip install numpy scipy matplotlib scikit-learn ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653691b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53796d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed the random number generators for reproducibility\n",
    "np.random.seed(100)\n",
    "\n",
    "# Initialize integrator keywords for solve_ivp to replicate the odeint defaults\n",
    "integrator_keywords = {}\n",
    "integrator_keywords['rtol'] = 1e-12\n",
    "integrator_keywords['method'] = 'RK45' #'LSODA'\n",
    "integrator_keywords['atol'] = 1e-12\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 1. Generate Noisy Lotka-Volterra System Data\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Lotka-Volterra system parameters\n",
    "alpha, beta, gamma, delta  = 4.0, 0.2, 9.0, 0.25\n",
    "params = [alpha, beta, gamma, delta]\n",
    "\n",
    "# Initial conditions x0, time step dt, and time span tspan\n",
    "x0 = [4.0,30.0]\n",
    "dt = 0.01\n",
    "t_span = (0, 5)\n",
    "t_eval = np.arange(t_span[0], t_span[1] + dt, dt)\n",
    "\n",
    "# Lotka-Volterra system right-hand side function\n",
    "def lotka_volterra_system(t, x, params):\n",
    "    dx = params[0] * x[0] - params[1] * x[0] * x[1]\n",
    "    dy = -params[2] * x[1] + params[3] * x[0] * x[1]\n",
    "    return [dx, dy]\n",
    "\n",
    "# Solve the initial value problem: Runga-Kutta method\n",
    "solution = solve_ivp(\n",
    "    fun=lotka_volterra_system,\n",
    "    t_span=t_span,\n",
    "    y0=x0,\n",
    "    args=(params,),\n",
    "    t_eval=t_eval,\n",
    "    **integrator_keywords\n",
    ")\n",
    "x_true = solution.y.T\n",
    "\n",
    "# Add Gaussian white noise\n",
    "np.random.seed(1)\n",
    "sig = 0.1\n",
    "x_noisy = x_true + sig * np.std(x_true) * np.random.randn(*x_true.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc5a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the noisy data\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(t_eval, x_noisy[:, 0], 'b', label='Prey (noisy)')\n",
    "plt.plot(t_eval, x_noisy[:, 1], 'r', label='Predator (noisy)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Population')\n",
    "plt.title('Noisy Lotka-Volterra Data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab305bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# 2. Compute Derivatives (finite difference)\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Compute derivatives using finite difference (4th order central difference)\n",
    "dx_dt = (1/(12*dt)) * (-x_noisy[5:, :] + 8*x_noisy[4:-1, :] - 8*x_noisy[2:-3, :] + x_noisy[1:-4, :])\n",
    "x = x_noisy[3:-2, :] # cut tails\n",
    "t = t_eval[3:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccb6c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# 3. Build library of nonlinear terms\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Build the library using the pooldata function defined in utils.py\n",
    "\n",
    "def poolData(x, polyorder):\n",
    "    \"\"\"Builds a polynomial library of candidate functions.\"\"\"\n",
    "\n",
    "    # If the input is a 1D array, convert it to a 2D array for consistent processing.\n",
    "    if x.ndim == 1:\n",
    "        x = x.reshape(1, -1)\n",
    "    \n",
    "    n_samples, n_vars = x.shape\n",
    "    ind = 0\n",
    "    # Add a column for the constant term (1)\n",
    "    theta = np.ones((n_samples, 1))\n",
    "    ind += 1\n",
    "\n",
    "    # Poly order 1\n",
    "    for i in range(n_vars):\n",
    "        theta = np.hstack([theta, x[:, i:i+1]])\n",
    "        ind += 1\n",
    "    \n",
    "    # Poly order 2\n",
    "    if polyorder >= 2:\n",
    "        for i in range(n_vars):\n",
    "            for j in range(i, n_vars):\n",
    "                theta = np.hstack([theta, (x[:, i] * x[:, j]).reshape(-1, 1)])\n",
    "                ind += 1\n",
    "\n",
    "    # Poly order 3\n",
    "    if polyorder >= 3:\n",
    "        for i in range(n_vars):\n",
    "            for j in range(i, n_vars):\n",
    "                for k in range(j, n_vars):\n",
    "                    theta = np.hstack([theta, (x[:, i] * x[:, j] * x[:, k]).reshape(-1, 1)])\n",
    "                    ind += 1\n",
    "    \n",
    "    return theta\n",
    "\n",
    "\n",
    "# polynomials up to order 3\n",
    "polyorder = 3 \n",
    "theta = poolData(x, polyorder)\n",
    "\n",
    "print(\"the library matrix theta has\", theta.shape[0], \"rows (time steps), and\", theta.shape[1], \"columns (nonlinear library terms).\")\n",
    "\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9b325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform sparse regression to identify the governing equations\n",
    "# Using ARD regression from sklearn\n",
    "reg = linear_model.ARDRegression()\n",
    "coef1 = reg.fit(theta, dx_dt[:, 0]).coef_\n",
    "coef2 = reg.fit(theta, dx_dt[:, 1]).coef_\n",
    "xi = np.vstack([coef1, coef2]).T\n",
    "\n",
    "print(\"Identified coefficients:\")\n",
    "print(np.round(xi, 4))\n",
    "\n",
    "## ---- Implement your own sparse regression method too here ---- ##\n",
    "# Perform sparse regression to identify the governing equations\n",
    "# (Your own sparse regression code here)\n",
    "\n",
    "## ---- Implement your own sparse regression method too here ---- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c997c9f",
   "metadata": {},
   "source": [
    "**Can you implement your own model selection algorithm based on Bayesian Evidence?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c888590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# 5 Evaluate Performance of BINDy Model for Forecasting\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Define the BINDy ODE function for integration\n",
    "def bindy_ode(t, x, params):\n",
    "    # This function needs the 'poolData' and 'xi' from the main script\n",
    "    theta_ode = poolData(x, params['polyorder'])\n",
    "    dx = (theta_ode @ params['xi']).flatten()\n",
    "    return dx\n",
    "\n",
    "# Parameters for the ODE solver\n",
    "sindy_params = {'xi': xi, 'polyorder': polyorder}\n",
    "\n",
    "# test trajectory from new initial condition\n",
    "x0_test = x_true[-1, :]\n",
    "t_test = t_eval\n",
    "\n",
    "# solve the initial value problem\n",
    "solution = solve_ivp(\n",
    "    fun=lotka_volterra_system,\n",
    "    t_span=t_span,\n",
    "    y0=x0_test,\n",
    "    args=(params,),\n",
    "    t_eval=t_test,\n",
    "    **integrator_keywords\n",
    ")\n",
    "x_test_true = solution.y.T\n",
    "\n",
    "# Simulate the learned model\n",
    "bindy_solution = solve_ivp(\n",
    "    fun=bindy_ode,\n",
    "    t_span=t_span,\n",
    "    y0=x0_test,\n",
    "    args=(sindy_params,),\n",
    "    t_eval=t_eval,\n",
    "    **integrator_keywords\n",
    ")\n",
    "x_bindy_sim = bindy_solution.y.T\n",
    "\n",
    "# Plot the results and compare\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(t_test, x_test_true[:, 0], 'b', label='True Prey')\n",
    "plt.plot(t_test, x_bindy_sim[:, 0], 'r--', label='BINDy Prey')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Population')\n",
    "plt.title('Prey Population: True vs BINDy')\n",
    "plt.legend()    \n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(t_test, x_test_true[:, 1], 'b', label='True Predator')\n",
    "plt.plot(t_test, x_bindy_sim[:, 1], 'r--', label='BINDy Predator')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Population')\n",
    "plt.title('Predator Population: True vs BINDy')\n",
    "plt.legend()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbee5c5c",
   "metadata": {},
   "source": [
    "# The real challenge\n",
    "Real-life predator and prey dynamics rarely obey such simple law. Nonethless, the equation captures the essential dynamics. \n",
    "\n",
    "The challenge, therefore, is to find better model that is \n",
    "- more realistically reflecting reality\n",
    "- more accurate in forecasting\n",
    "\n",
    "For example, in the classic Lotka Voltera model, prey are expected to grow exponentially in the absence of predators, unbounded by food. A biologically relevant alternative to the classic Lotka Volterra model is to include a carrying capacity ($Κ$) into the prey population.\n",
    "$$\\frac{dx}{dt}=\\alpha x\\left(1-\\frac{x}{Κ}\\right) - \\beta x y$$\n",
    "$$\\frac{dy}{dt}=\\delta x y - \\gamma y$$\n",
    "\n",
    "This represent's the dynamics of the prey being limited by the constraints in the environment, such that in the absence of predators, the prey population tends to $Κ$, rather than $∞$.\n",
    "\n",
    "Similarly, the death rate can be regularised:\n",
    "$$\\frac{dx}{dt}=\\alpha x\\left(1-\\frac{x}{Κ}\\right) - \\beta \\frac{x y}{c+x}$$\n",
    "$$\\frac{dy}{dt}=\\delta \\frac{x y}{c+x} - \\gamma y$$\n",
    "\n",
    "where $c$ is called Michaelis constant, taking inspiration from the [Michaelis-Menten equation](https://en.wikipedia.org/wiki/Michaelis%E2%80%93Menten_kinetics).\n",
    "\n",
    "### Other things to think about\n",
    "- The populations can become arbitrarily low and still recover – extinction is impossible\n",
    "- The equations are deterministic, but the system is inherently stochastic\n",
    "- Doesn’t consider long-term external factors (e.g. weather and infectious diseases)\n",
    "- The data is based on pelts trade, which might not always be representative of the real population dynamics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc898b1",
   "metadata": {},
   "source": [
    "## Your Project\n",
    "**Your challenge is to come up with an even \"better\" model based on real-life data.**\n",
    "-  You're free to define what is \"better\" to you - e.g. better forecast? better generalisability? better interpreted? closer to ground truth?\n",
    "-  How would you evaluate your improvement to the model based on the data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215bf7c0",
   "metadata": {},
   "source": [
    "## About the data\n",
    "The Hudson Bay Company kept a good record on the number of animal they caught for pelts in Canada between 1845 to 1935, in which the two animals of focus are the lynx (predator) and snowshoe hare (prey). \n",
    "\n",
    "To get started, use the [data between 1900-1920](https://jmahaffy.sdsu.edu/courses/f00/math122/labs/labj/lotvol.xls).\n",
    "\n",
    "If you want more data, here's [another source](http://people.whitman.edu/~hundledr/courses/M250F03/LynxHare.txt) for the year between 1845-1935.\n",
    "\n",
    "### Some notes about the data\n",
    "The data is directly measure the animal's population, but the number the company managed to trap for pelts. To use it directly as population data, we are assuming that there is a linear relationship between the pelts trade and the population. How would that affect your modelling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453ea67d",
   "metadata": {},
   "source": [
    "## Some foreseeable challenges\n",
    "However, real data is not as friendly to the learning algorithm. \n",
    "Foreseeable challenges include:\n",
    "- Much scarcer data\n",
    "  - Low Sampling rate\n",
    "- Inaccuracy in the way $d/dt$ is computed\n",
    "  - Can we improve it? \n",
    "- Much noisier data\n",
    "  - How to determine the noise level?\n",
    "- Stochastic noise AND measurement noise\n",
    "  - How to distinguish between the two?\n",
    "\n",
    "### Some inspiration for you to get started with the library design\n",
    " - https://mc-stan.org/learn-stan/case-studies/lotka-volterra-predator-prey.html\n",
    " - https://jckantor.github.io/CBE30338/02.05-Hare-and-Lynx-Population-Dynamics.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22c569b",
   "metadata": {},
   "source": [
    "## How you'd be assessed\n",
    "The main aim of the project is to let you exercise the workflow from data collection, to the design of library, model selection and validation. It is open-ended, so you are not necessarily required to get a very accurate model out of the data. However, it is important that you have demonstrated that you can:\n",
    "- implement the workflow from data collection to library design and model selection by your own code\n",
    "- explain the rationale behind the chosen library (e.g. why polynomial library? why not rational/trigonometric functions?)\n",
    "- justifying the model selected through the Bayesian framework (i.e. why this model and not the others?)\n",
    "  - in particular, justify the hyperparameters used and how they affect the learning result\n",
    "- interpret the learning result and the model selected\n",
    "- test/validate the learning result and the model selected\n",
    "- communicate well the learning result to others\n",
    "- show how the current method or learning result can be further improved\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
