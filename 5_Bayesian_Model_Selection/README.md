# BayesianModelSelection
Tutorial on (sparse) Model Selection using various Bayesian principles

## Learning Outcome
- Understand the principle of Occam razor and its Bayesian interpretation
- Gain an intuition to the scaling of prior and likelihood with data and noise
- Able to interpret Information Criterions from the Bayesian evidence perspective
- (Understand the mechanism of sparsification from Bayes' point of view)
- (Applying sparsifying prior to promote sparsity in model creation)

## Reference Material
- Books:
  - A. C. Faul - A Concise Introduction to Machine Learning
  - D. J. C. MacKay - Information Theory, Inference, and Learning Algorithms

## Tutorial Notebook
### Shortcuts
Go to the tutorial notebook:  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jonathon-langford/aims-inference-2026/blob/main/5_Bayesian_Model_Selection/Polynomial.ipynb)

Go to the tutorial notebook (with solution):  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jonathon-langford/aims-inference-2026/blob/main/5_Bayesian_Model_Selection/solution/Polynomial_Solution.ipynb)

### Tested Python Version
python = 3.14.2
scipy = 1.17.0
numpy = 2.4.1
sklearn. = 1.8.0